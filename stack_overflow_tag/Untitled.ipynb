{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center\"> Stack Overflow: Tag Prediction </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../images/so_tag/pic1.jpg'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from wordcloud import WordCloud\n",
    "import re\n",
    "import os\n",
    "from sqlalchemy import create_engine # database connection\n",
    "import datetime as dt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score,precision_score,recall_score\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from skmultilearn.adapt import mlknn\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from datetime import datetime\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='font-size:24px'><b> Description </b></p>\n",
    "<p>\n",
    "Stack Overflow is the largest, most trusted online community for developers to learn, share their programming knowledge, and build their careers.<br />\n",
    "<br />\n",
    "Stack Overflow is something which every programmer use one way or another. Each month, over 50 million developers come to Stack Overflow to learn, share their knowledge, and build their careers. It features questions and answers on a wide range of topics in computer programming. The website serves as a platform for users to ask and answer questions, and, through membership and active participation, to vote questions and answers up or down and edit questions and answers in a fashion similar to a wiki or Digg. As of April 2014 Stack Overflow has over 4,000,000 registered users, and it exceeded 10,000,000 questions in late August 2015. Based on the type of tags assigned to questions, the top eight most discussed topics on the site are: Java, JavaScript, C#, PHP, Android, jQuery, Python and HTML.<br />\n",
    "<br />\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='font-size:18px'><b> Problem Statemtent </b></p>\n",
    "Suggest the tags based on the content that was there in the question posted on Stackoverflow.\n",
    "\n",
    "<p style='font-size:18px'><b> Source:  </b> https://www.kaggle.com/c/facebook-recruiting-iii-keyword-extraction/</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Business Objectives and Constraints </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Predict as many tags as possible with high precision and recall.\n",
    "2. Incorrect tags could impact customer experience on StackOverflow.\n",
    "3. No strict latency constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Data </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer: https://www.kaggle.com/c/facebook-recruiting-iii-keyword-extraction/data\n",
    "<br>\n",
    "All of the data is in 2 files: Train and Test.<br />\n",
    "<pre>\n",
    "<b>Train.csv</b> contains 4 columns: Id,Title,Body,Tags.<br />\n",
    "<b>Test.csv</b> contains the same columns but without the Tags, which you are to predict.<br />\n",
    "<b>Size of Train.csv</b> - 6.75GB<br />\n",
    "<b>Size of Test.csv</b> - 2GB<br />\n",
    "<b>Number of rows in Train.csv</b> = 6034195<br />\n",
    "</pre>\n",
    "The questions are randomized and contains a mix of verbose text sites as well as sites related to math and programming. The number of questions from each site may vary, and no filtering has been performed on the questions (such as closed questions).<br />\n",
    "<br />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Data Field Explaination__\n",
    "\n",
    "Dataset contains 6,034,195 rows. The columns in the table are:<br />\n",
    "<pre>\n",
    "<b>Id</b> - Unique identifier for each question<br />\n",
    "<b>Title</b> - The question's title<br />\n",
    "<b>Body</b> - The body of the question<br />\n",
    "<b>Tags</b> - The tags associated with the question in a space-seperated format (all lowercase, should not contain tabs '\\t' or ampersands '&')<br />\n",
    "</pre>\n",
    "\n",
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Mapping to a Machine Learning Problem </h2>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> It is a multi-label classification problem  <br>\n",
    "<b>Multi-label Classification</b>: Multilabel classification assigns to each sample a set of target labels. This can be thought as predicting properties of a data-point that are not mutually exclusive, such as topics that are relevant for a document. A question on Stackoverflow might be about any of C, Pointers, FileIO and/or memory-management at the same time or none of these. <br>\n",
    "__Credit__: http://scikit-learn.org/stable/modules/multiclass.html\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Performance metric </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Micro-Averaged F1-Score (Mean F Score) </b>: \n",
    "The F1 score can be interpreted as a weighted average of the precision and recall, where an F1 score reaches its best value at 1 and worst score at 0. The relative contribution of precision and recall to the F1 score are equal. The formula for the F1 score is:\n",
    "\n",
    "<i>F1 = 2 * (precision * recall) / (precision + recall)</i><br>\n",
    "\n",
    "In the multi-class and multi-label case, this is the weighted average of the F1 score of each class. <br>\n",
    "\n",
    "<b>'Micro f1 score': </b><br>\n",
    "Calculate metrics globally by counting the total true positives, false negatives and false positives. This is a better metric when we have class imbalance.\n",
    "<br>\n",
    "\n",
    "<b>'Macro f1 score': </b><br>\n",
    "Calculate metrics for each label, and find their unweighted mean. This does not take label imbalance into account.\n",
    "<br>\n",
    "\n",
    "https://www.kaggle.com/wiki/MeanFScore <br>\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html <br>\n",
    "<br>\n",
    "<b> Hamming loss </b>: The Hamming loss is the fraction of labels that are incorrectly predicted. <br>\n",
    "https://www.kaggle.com/wiki/HammingLoss <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('../data/so_tag/._lr_with_more_title_weight.pkl'),\n",
       " PosixPath('../data/so_tag/OpenedFilesView.exe'),\n",
       " PosixPath('../data/so_tag/Test.csv'),\n",
       " PosixPath('../data/so_tag/tokenaizer.JPG'),\n",
       " PosixPath('../data/so_tag/._Titlemoreweight.db'),\n",
       " PosixPath('../data/so_tag/._tokenaizer.JPG'),\n",
       " PosixPath('../data/so_tag/train_no_dup-003.db'),\n",
       " PosixPath('../data/so_tag/._train_no_dup-003.db'),\n",
       " PosixPath('../data/so_tag/._SO_Tag_Predictor.ipynb'),\n",
       " PosixPath('../data/so_tag/._lr_with_equal_weight-002.pkl'),\n",
       " PosixPath('../data/so_tag/._Processed.db'),\n",
       " PosixPath('../data/so_tag/Processed.db'),\n",
       " PosixPath('../data/so_tag/lr_with_equal_weight-002.pkl'),\n",
       " PosixPath('../data/so_tag/SO_Tag_Predictor.ipynb'),\n",
       " PosixPath('../data/so_tag/SampleSubmission.csv'),\n",
       " PosixPath('../data/so_tag/lr_with_more_title_weight.pkl'),\n",
       " PosixPath('../data/so_tag/Titlemoreweight.db'),\n",
       " PosixPath('../data/so_tag/._tag_counts_dict_dtm.csv'),\n",
       " PosixPath('../data/so_tag/Train.csv'),\n",
       " PosixPath('../data/so_tag/tag_counts_dict_dtm.csv'),\n",
       " PosixPath('../data/so_tag/._OpenedFilesView.exe')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path('../data/so_tag')\n",
    "list(path.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180000 rows\n",
      "360000 rows\n",
      "540000 rows\n",
      "720000 rows\n",
      "900000 rows\n",
      "1080000 rows\n",
      "1260000 rows\n",
      "1440000 rows\n",
      "1620000 rows\n",
      "1800000 rows\n",
      "1980000 rows\n",
      "2160000 rows\n",
      "2340000 rows\n",
      "2520000 rows\n",
      "2700000 rows\n",
      "2880000 rows\n",
      "3060000 rows\n",
      "3240000 rows\n",
      "3420000 rows\n",
      "3600000 rows\n",
      "3780000 rows\n",
      "3960000 rows\n",
      "4140000 rows\n",
      "4320000 rows\n",
      "4500000 rows\n",
      "4680000 rows\n",
      "4860000 rows\n",
      "5040000 rows\n",
      "5220000 rows\n",
      "5400000 rows\n",
      "5580000 rows\n",
      "5760000 rows\n",
      "5940000 rows\n",
      "6120000 rows\n",
      "Time taken to run this cell : 0:03:41.212066\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "disk_engine = create_engine('sqlite:///train.db')\n",
    "chunksize = 180000\n",
    "j = 0\n",
    "index_start = 1\n",
    "for df in pd.read_csv(path/'Train.csv', names=['Id', 'Title', 'Body', 'Tags'], chunksize=chunksize, iterator=True, encoding='utf-8'):\n",
    "    df.index += index_start\n",
    "    j+=1\n",
    "    print('{} rows'.format(j*chunksize))\n",
    "    df.to_sql('data', disk_engine, if_exists='append')\n",
    "    index_start = df.index[-1] + 1\n",
    "print(\"Time taken to run this cell :\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the database : \n",
      " 6034196\n",
      "Time taken to count the number of rows : 0:00:00.104634\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "con = sqlite3.connect('train.db')\n",
    "num_rows = pd.read_sql_query(\"\"\"SELECT count(*) FROM data\"\"\", con)\n",
    "#Always remember to close the database\n",
    "print(\"Number of rows in the database :\",\"\\n\",num_rows['count(*)'].values[0])\n",
    "con.close()\n",
    "print(\"Time taken to count the number of rows :\", datetime.now() - start)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to run this cell : 0:01:32.577932\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "con = sqlite3.connect('train.db')\n",
    "df_duplicates = pd.read_sql_query('SELECT title, body, tags, COUNT(*) as cnt_dup FROM data GROUP BY title, body, tags', con)\n",
    "con.close()\n",
    "print(\"Time taken to run this cell :\", datetime.now() - start)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Tags</th>\n",
       "      <th>cnt_dup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Implementing Boundary Value Analysis of S...</td>\n",
       "      <td>&lt;pre&gt;&lt;code&gt;#include&amp;lt;iostream&amp;gt;\\n#include&amp;...</td>\n",
       "      <td>c++ c</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dynamic Datagrid Binding in Silverlight?</td>\n",
       "      <td>&lt;p&gt;I should do binding for datagrid dynamicall...</td>\n",
       "      <td>c# silverlight data-binding</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dynamic Datagrid Binding in Silverlight?</td>\n",
       "      <td>&lt;p&gt;I should do binding for datagrid dynamicall...</td>\n",
       "      <td>c# silverlight data-binding columns</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>java.lang.NoClassDefFoundError: javax/serv...</td>\n",
       "      <td>&lt;p&gt;I followed the guide in &lt;a href=\"http://sta...</td>\n",
       "      <td>jsp jstl</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>java.sql.SQLException:[Microsoft][ODBC Dri...</td>\n",
       "      <td>&lt;p&gt;I use the following code&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;...</td>\n",
       "      <td>java jdbc</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0       Implementing Boundary Value Analysis of S...   \n",
       "1           Dynamic Datagrid Binding in Silverlight?   \n",
       "2           Dynamic Datagrid Binding in Silverlight?   \n",
       "3      java.lang.NoClassDefFoundError: javax/serv...   \n",
       "4      java.sql.SQLException:[Microsoft][ODBC Dri...   \n",
       "\n",
       "                                                Body  \\\n",
       "0  <pre><code>#include&lt;iostream&gt;\\n#include&...   \n",
       "1  <p>I should do binding for datagrid dynamicall...   \n",
       "2  <p>I should do binding for datagrid dynamicall...   \n",
       "3  <p>I followed the guide in <a href=\"http://sta...   \n",
       "4  <p>I use the following code</p>\\n\\n<pre><code>...   \n",
       "\n",
       "                                  Tags  cnt_dup  \n",
       "0                                c++ c        1  \n",
       "1          c# silverlight data-binding        1  \n",
       "2  c# silverlight data-binding columns        1  \n",
       "3                             jsp jstl        1  \n",
       "4                            java jdbc        2  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_duplcates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4206315, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_duplcates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total duplicate rows 30.292038906260256\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total duplicate rows {((num_rows['count(*)'].values[0] - df_duplcates.shape[0]) / num_rows['count(*)'].values[0]) * 100}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_rows.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6034196"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_rows['count(*)'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
